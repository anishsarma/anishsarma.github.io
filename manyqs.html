<!DOCTYPE html>
<html lang="en">
    <head>
        <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X0R6WGHXD1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-X0R6WGHXD1');
</script>
        <title>Many questions in one</title>
        <meta charset="utf-8">
               <link rel="stylesheet" href="main.css">
    </head>
    <body onload="toggleExtrasShow('shortlist','toggleshort');">
        <script src="sort-table.js"></script>
        
<h1>Many questions in one</h1>
Different fields value different indicators of success and rigor. Theoretical fields value the soundness of mathematical arguments from premises. Experimental fields value the systematic consideration of alternative explanations through careful observation and intervention. Clinical fields (and other applied fields) value patient outcomes (or other performance outcomes) at scale. 
<br><br>
This also means that there are standards that each field doesn’t value. The theorist might say, “I don’t care about every detailed observation – I care that within reasonable assumptions, my conclusions are sound.” The experimentalist might say, “I don’t care about what might be happening somewhere I’ll never observe – I care that I get the things that I can observe right.” The clinician might say, “I don’t care about <i>how</i> it works – I care <i>that</i> it works.”
<br><br>
Ideally, we care about all of these standards, and they all reinforce each other. We want to know how a system works, the parts we can observe and the parts we can’t, so that we can achieve better outcomes. For problems in the life sciences, I think it is useful to consider specific methodological approaches for the reconciliation of the theoretical, the experimental, and the applied. 
<br><br>
Let’s take an applied problem, like, “What kinds of interventions would reduce rates of cancer in adults with a smoking history?” This leads naturally to several basic science questions. “Why do some people with a smoking history get cancer while others don’t?” leads to “What kinds of processes make people vulnerable to cancer, and how do they vary across people?” leads to “What kinds of mechanisms protect organisms from cancer, and how do they vary across individuals and species?”
<br><br>
Since these are already big enough questions to motivate several years of clinical or basic research, we might consider stopping there. We could follow a well-worn path: (1) identify some Molecule X that is correlated with higher rates of post-smoking lung cancer, (2) verify in appropriate experimental systems that inhibiting Molecule X decreases rates of post-smoking lung cancer phenotypes and supplementing Molecule X increases rates of post-smoking lung cancer phenotypes, and (3) design a series of safety and efficacy clinical studies, culminating in a randomized control trial, to treat individuals at risk for post-smoking lung cancer with Molecule X Inhibitors and measure their rates of lung cancer development. 
<br><br>
What if no Molecule X can be found? What if there is a Molecule X correlated with higher rates of post-smoking lung cancer, but inhibiting Molecule X has no apparent effect on post-smoking lung cancer phenotypes in experiments? What if inhibiting Molecule X reduces rates of post-smoking lung cancer phenotypes in experiments, but in randomized control trials, there is no apparent effect on real-world outcomes? 
<br><br>
These what-ifs describe the fate of the <a href = "https://www.nature.com/articles/d41573-019-00074-z">overwhelming majority</a> of basic-to-applied translational efforts. Of course, efforts that don’t yield widely adopted therapies can be successful and informative in other ways, and it would be unreasonable to expect that every promising preclinical idea achieved its maximal clinical potential. Improving translational yield is an important goal, but I want to elaborate on an even more elementary point. The typical translational path is reasonable for certain kinds of systems: those in which molecules match one-to-one with phenotypes and are homologous across species, in which anything we haven’t measured can be aggregated into benign noise that we can mostly overcome with statistical tests. Crucially, <i>we already know that other kinds of systems can exist</i>. 
<br><br>
Suppose we were studying the activity of a car’s brakes, but we didn’t know anything about drivers. We would notice that cars whose brakes were constantly applied tended not to leave the lot. But if we tried to fix this problem by removing the brakes from those cars, then for entirely different reasons, those cars wouldn’t leave the lot either.
<br><br>
When we encounter some of the expected difficulties translating the basic to the applied, we can take steps to make sure we aren’t studying cars without studying drivers. We necessarily start to ask questions like, “What kinds of systems <i>could</i> we be dealing with?” and “What kinds of multicellular systems develop cancer, and what kinds of systems don’t?” and “What kinds of multicellular systems can exist?” (A lifetime of statistical training might create the compulsion to say that some systems are <i>more or less likely</i> to exist, but any working engineer knows that some systems under some constraints are plainly <i>infeasible</i>.) For systems with only two or three interacting parts, we might be able to talk through these questions informally at a whiteboard. For larger systems, with more interactions and more feedback, these questions are at the boundary of expert intuition, and at the boundary of what we have rigorous and broadly applicable theory or computational tools to describe. 
<br><br>
At this point, one might start to worry that we are becoming preoccupied with epistemological questions that, however important and interesting they might be, will not yield practical applications in a lifetime. This concern is reasonable, but misplaced in an era of computer-aided discovery and design. Characterization of systems that can or can’t exist is essential for ruling out hypotheses; it is also, less obviously, an accelerating step in engineering design. The successful characterization helps you target new tools at the lab bench to modulate your system more dramatically, reveal new behaviors, respond to new contexts. The same tools that allow you to design new experiments at the bench allow you to design new interventions. In this way, when the clinician asks, “What works?” and the experimentalist asks, “How does it work?” and the theorist asks, “What might work?” – they are all asking the same question.
        <br><br>
    </body>
</html>
